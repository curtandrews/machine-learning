{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine_lerning_(3)_(1) (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "gmGRQlxOgkx1"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1P3laA0lghe5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import PIL as pil\n",
        "from PIL import Image\n",
        "from PIL.Image import fromarray\n",
        "import os\n",
        "import csv\n",
        "import google.protobuf\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout, Conv2D, MaxPooling2D, Input, Conv2DTranspose, concatenate, UpSampling2D\n",
        "from IPython.display import Image, display\n",
        "import sys\n",
        "import threading\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Activation\n",
        "from keras import backend as K\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "from tempfile import TemporaryFile\n",
        "from random import shuffle\n",
        "\n",
        "print(tf.VERSION)\n",
        "print(tf.keras.__version__)\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VJb-VPqFGarw"
      },
      "cell_type": "markdown",
      "source": [
        "# Utility functions\n",
        "Here functions for datainteraction are defined\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PcKOEWRUHKMf"
      },
      "cell_type": "markdown",
      "source": [
        "**Picture information saving class**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dbgpC5uAVngZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class pixel_array:\n",
        " __coordinate=0\n",
        " __length=0\n",
        " \n",
        " def __init__(self, coordinate, length):\n",
        "  self.__coordinate = int (coordinate)\n",
        "  self.__length = int (length)\n",
        " \n",
        " def setCoordinate(self, xCoordinate):\n",
        "    self.__coordinate = coordinate\n",
        " \n",
        " def setLength(self, yCoordinate):\n",
        "    self.__length = length\n",
        "   \n",
        " def get_coordinate(self):\n",
        "    return int(self.__coordinate)\n",
        "   \n",
        " def get_length(self):\n",
        "    return int(self.__length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SywJsM3RFlZA"
      },
      "cell_type": "markdown",
      "source": [
        "**Plot the history**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9pm4nHfVezl3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plotHistory(iou_array, val_iou_array):\n",
        "    \n",
        "  fig = plt.figure(figsize=(12, 6))\n",
        "  ax = fig.add_subplot(1, 2, 1)\n",
        "  ax.plot(iou_array,'r-x', label=\"Train IOU\")\n",
        "  ax.legend()\n",
        "  ax.set_title('iou accuracy')\n",
        "  ax.grid(True)\n",
        "  ax.plot(val_iou_array,'b-x', label=\"Validation IOU\")\n",
        "  ax.legend()\n",
        "  ax.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Wr13L-siHFgU"
      },
      "cell_type": "markdown",
      "source": [
        "**Get labels from file as dictionary of pixel_array with image name as key**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ku5-fu0v_0II",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def readMarkedPixels(path):\n",
        "   num_lines = sum(1 for line in open(path))\n",
        "   num_lines = num_lines-1\n",
        "   with open(path, mode='r') as csv_file:\n",
        "    csv_reader = csv.DictReader(csv_file)\n",
        "    line_count = 0\n",
        "    data = {}\n",
        "    for row in tqdm(csv_reader, total=num_lines, unit=\"rows\"):\n",
        "\n",
        "     pixelData = row['EncodedPixels'].split(' ')\n",
        "     counter = 0\n",
        "     pixels = []\n",
        "\n",
        "     while counter < len(pixelData)-1:\n",
        "      pixels.append(pixel_array(pixelData[counter], pixelData[counter+1]))\n",
        "      counter += 2\n",
        "     image_id = row['ImageId']\n",
        "     try:\n",
        "      data[image_id].extend(pixels)\n",
        "     except Exception as e:\n",
        "      data[image_id] = pixels\n",
        "      \n",
        "     if len(data[image_id])<10:\n",
        "      data[image_id] = []\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6MmCFvH5Ypz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Batch separation function**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DTp1VgbOMtlR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getBatchList(batch_size, index, all_list):\n",
        "    return all_list[index*batch_size:(index+1)*batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tkjcrhh4lXR5"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "The following chapter handels the creation of Masks from the given data."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8B-8MCLZF1Oz"
      },
      "cell_type": "markdown",
      "source": [
        "**Creating the Mask Thread**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cWEEfCQrKFgu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class createLabelsThread(threading.Thread):\n",
        "\n",
        "    def __init__(self, marked_pixels, work_list, target_path, group=None, target=None, name=None,\n",
        "                 args=(), kwargs=None, verbose=None):\n",
        "        threading.Thread.__init__(self, group=group, target=target, name=name)\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.work_list = work_list\n",
        "        self.marked_pixels = marked_pixels\n",
        "        self.target_path = target_path\n",
        "        return\n",
        "\n",
        "    def run(self):\n",
        "        for key in self.work_list:\n",
        "          temp_label = np.zeros((768**2))\n",
        "          for pixel_arrays in self.marked_pixels[key]:\n",
        "            for i in range(pixel_arrays.get_length()):\n",
        "              try:\n",
        "                temp_label[pixel_arrays.get_coordinate()-1 + i] = 1\n",
        "              except:\n",
        "                print(\"except in : \" + str(key))\n",
        "          temp_label.tofile(self.target_path + key + \".data\")\n",
        "        return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kPqX7bVhGAiG"
      },
      "cell_type": "markdown",
      "source": [
        "**Execute Mask creation**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "MhRu3Q8G-osW"
      },
      "cell_type": "markdown",
      "source": [
        "Training Masks\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aizg9qqIQJFs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get label data\n",
        "marked_train_pixels = readMarkedPixels('./train_label.csv')\n",
        "\n",
        "# Split data into containing and not containing ships\n",
        "img_cont_ship = []\n",
        "img_no_cont_ship = []\n",
        "counter = 0\n",
        "contain_ships = 0\n",
        "for key in marked_train_pixels:\n",
        "  counter +=1\n",
        "  if len(marked_train_pixels[key]) != 0:\n",
        "    contain_ships += 1\n",
        "    img_cont_ship.append(key)\n",
        "  else:\n",
        "    img_no_cont_ship.append(key)\n",
        "  \n",
        "print(\"number of ships: \" + str(contain_ships))\n",
        "print(\"number of non_ships: \" + str(counter))\n",
        "print(\"contain ships: \" + str(contain_ships * 100/counter) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qKVcmLPDBQpw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create train labels with Multithreading\n",
        "\n",
        "marked_train_pixels = readMarkedPixels('./train_label.csv')\n",
        "\n",
        "threads = []\n",
        "\n",
        "batch_size = 1250\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 0, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 1, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 2, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 3, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 4, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 5, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 6, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 7, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 8, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 9, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 10, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 11, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 12, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 13, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 14, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 15, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 16, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 17, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 18, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 19, img_cont_ship), target_path = \"./train_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 0, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 1, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 2, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 3, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 4, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 5, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 6, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 7, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 8, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_train_pixels, work_list = getBatchList(batch_size, 9, img_no_cont_ship), target_path = \"./train_label_no_ship/\"))\n",
        "\n",
        "for t in threads:\n",
        "  t.start()\n",
        "  \n",
        "print(\"waiting for finish...\")\n",
        "\n",
        "for t in threads: \n",
        "  t.join()\n",
        "  \n",
        "print(\"finished!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LhT2Vna3_Cfh"
      },
      "cell_type": "markdown",
      "source": [
        "Test Masks\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vt6uVm4a_JWr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get Label data\n",
        "marked_test_pixels = readMarkedPixels('./test_label.csv')\n",
        "\n",
        "\n",
        "# Split data into containing and not containing ships\n",
        "test_img_cont_ship = []\n",
        "test_img_no_cont_ship = []\n",
        "test_counter = 0\n",
        "test_contain_ships = 0\n",
        "for key in marked_test_pixels:\n",
        "  test_counter +=1\n",
        "  if len(marked_test_pixels[key]) != 0:\n",
        "    test_contain_ships += 1\n",
        "    test_img_cont_ship.append(key)\n",
        "  else:\n",
        "    test_img_no_cont_ship.append(key)\n",
        "  \n",
        "print(\"number of ships: \" + str(test_contain_ships))\n",
        "print(\"number of non_ships: \" + str(len(test_img_no_cont_ship)))\n",
        "print(\"contain ships: \" + str(test_contain_ships * 100/test_counter) + \"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "macJBG4E_gce",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create test labels with Multithreading## create labels\n",
        "\n",
        "marked_test_pixels = readMarkedPixels('./test_label.csv')\n",
        "\n",
        "threads = []\n",
        "\n",
        "batch_size = 1262\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 0, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 1, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 2, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 3, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 4, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 5, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 6, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 7, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 8, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 9, test_img_cont_ship), target_path = \"./test_label_ship/\"))\n",
        "\n",
        "\n",
        "batch_size = 3792\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 0, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 1, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 2, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 3, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 4, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 5, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 6, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 7, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 8, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 9, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 10, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 11, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 12, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 13, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 14, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 15, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 16, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 17, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 18, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "threads.append(createLabelsThread(marked_pixels = marked_test_pixels, work_list = getBatchList(batch_size, 19, test_img_no_cont_ship), target_path = \"./test_label_no_ship/\"))\n",
        "\n",
        "for t in threads:\n",
        "  t.start()\n",
        "  \n",
        "print(\"waiting for finish...\")\n",
        "\n",
        "for t in threads: \n",
        "  t.join()\n",
        "  \n",
        "print(\"finished!\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r2CU6c8Su-pv"
      },
      "cell_type": "markdown",
      "source": [
        "# Getting to know the data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hPdlpsI4G3UY"
      },
      "cell_type": "markdown",
      "source": [
        "**Visualisation of Original image and Mask**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MBjx2LhhV-cn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "display(Image(\"./train_data/6384c3e78.jpg\", width=300, height=300))\n",
        "plt.imshow(np.reshape(np.fromfile(\"./train_label/00aa60389.jpg.data\")*255, (768, 768)).T, cmap=\"gray\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BrD0GEJNMYi7"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0YEZqT_9MDdp"
      },
      "cell_type": "markdown",
      "source": [
        "** Define loss function and metrics**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OBL_bQX6d1n0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Iou metric\n",
        "def iou(y_true, y_pred):\n",
        "  thresh = 0\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  #calculate true positive, false negative and false positive values\n",
        "  true_positive = K.sum(y_true_f * y_pred_f)\n",
        "  false_negative = K.sum(y_true_f) - true_positive\n",
        "  false_positive = K.sum(y_pred_f) - true_positive\n",
        "  beta = 2\n",
        "  return K.cast(((1 + beta^2) * true_positive + thresh)/(((1 + beta^2) * true_positive) + (beta^2)*false_negative + false_positive + thresh), 'float32')\n",
        "\n",
        "# Back_iou metric\n",
        "def back_iou(y_true, y_pred):\n",
        "   return iou(1-y_true, 1-y_pred)\n",
        "  \n",
        "# Loss function\n",
        "def iou_loss(y_true, y_pred):\n",
        "  return K.cast(1, 'float32') - iou(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OQeQlW4RMJp7"
      },
      "cell_type": "markdown",
      "source": [
        "**Data generator**\n",
        "\n",
        "Providing the data as a pipeline."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5VlQT2uCoqpN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, read_path, batch_size=32, dim=(768,768), n_channels=3,\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.read_path = read_path\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "            \n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, 768, 768, self.n_channels))\n",
        "        y = np.empty((self.batch_size, 768, 768))\n",
        "\n",
        "        label_dir = self.read_path.split(\"_\")[0] + \"_label_no_ship/\"#\"_label_ship/\"\n",
        "        \n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store data\n",
        "            try:\n",
        "                X[i,] = np.asarray(pil.Image.open(self.read_path + ID))/255\n",
        "\n",
        "            # Store label\n",
        "                y[i] = np.reshape(np.fromfile(label_dir + ID + \".data\"), (768, 768, 1)).T\n",
        "            except Exception as e:\n",
        "              print(\"error in file: \" + str(ID))\n",
        "              print(str(e))\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUZDlQ9-7evL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating validation and and train datasets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TKr0bGi9tGWc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {'batch_size': 3,\n",
        "          'dim': (768,768),\n",
        "          'n_channels': 3,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Read filenames\n",
        "complete_data_list = os.listdir(\"./train_label_ship/\")\n",
        "for i, string in enumerate(complete_data_list):\n",
        "    complete_data_list[i] = string[:-5]\n",
        "\n",
        "shuffle(complete_data_list)\n",
        "\n",
        "print(str(complete_data_list[0]))\n",
        "print(len(complete_data_list))\n",
        "# Split dataset\n",
        "data1 = complete_data_list[0:6249]\n",
        "data2 = complete_data_list[6250:12499]\n",
        "data3 = complete_data_list[12500:18749]\n",
        "data4 = complete_data_list[18750:24999]\n",
        "\n",
        "# Create sets\n",
        "training_data_1 = data1\n",
        "training_data_1.extend(data2)\n",
        "training_data_1.extend(data3)\n",
        "validation_data_1 = data4\n",
        "\n",
        "training_data_2 = data1\n",
        "training_data_2.extend(data2)\n",
        "training_data_2.extend(data4)\n",
        "validation_data_2 = data3\n",
        "\n",
        "training_data_3 = data1\n",
        "training_data_3.extend(data3)\n",
        "training_data_3.extend(data4)\n",
        "validation_data_3 = data2\n",
        "\n",
        "training_data_4 = data2\n",
        "training_data_4.extend(data3)\n",
        "training_data_4.extend(data4)\n",
        "validation_data_4 = data1\n",
        "\n",
        "# Create data generators\n",
        "training_generator1 = DataGenerator(training_data_1, \"./train_data/\", **params)\n",
        "validation_generator1 = DataGenerator(validation_data_1, \"./train_data/\", **params)\n",
        "\n",
        "training_generator2 = DataGenerator(training_data_2, \"./train_data/\", **params)\n",
        "validation_generator2 = DataGenerator(validation_data_2, \"./train_data/\", **params)\n",
        "\n",
        "training_generator3 = DataGenerator(training_data_3, \"./train_data/\", **params)\n",
        "validation_generator3 = DataGenerator(validation_data_3, \"./train_data/\", **params)\n",
        "\n",
        "training_generator4 = DataGenerator(training_data_4, \"./train_data/\", **params)\n",
        "validation_generator4 = DataGenerator(validation_data_4, \"./train_data/\", **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "28jWLQFj8432",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define reusable learning function**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "h37HFU8zsW8Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def learn(save_model_path, training_generator, validation_generator, model):\n",
        "  # Compile\n",
        "  model.compile(optimizer=Adam(lr=1e-7), loss = iou_loss, metrics=[iou])\n",
        "  \n",
        "  # Create callbacks\n",
        "  checkpoint = ModelCheckpoint(save_model_path, monitor='val_iou', verbose=1, \n",
        "                               save_best_only=True, mode='max', save_weights_only = True)\n",
        "\n",
        "  early = EarlyStopping(monitor=\"val_iou\", \n",
        "                        mode=\"max\", \n",
        "                        patience=2)\n",
        "\n",
        "  callbacks_list = [checkpoint, early]\n",
        "\n",
        "\n",
        "  # Train model on dataset\n",
        "  history = model.fit_generator(generator=training_generator,\n",
        "                      validation_data=validation_generator,\n",
        "                      use_multiprocessing=True,\n",
        "                      epochs=50,\n",
        "                      workers=30,\n",
        "                      callbacks=callbacks_list,\n",
        "                      verbose=1)\n",
        "\n",
        "  # Save history\n",
        "  print(\"\\n\" + save_model_path + \" history:\")\n",
        "    \n",
        "  iou_val_history = history.history[\"val_iou\"]\n",
        "  numpy_val_iou_history = np.array(iou_val_history)\n",
        "  np.savetxt(save_model_path[:-3]+\"_val_iou_history.txt\", numpy_val_iou_history, delimiter=\",\")\n",
        " \n",
        "  iou_history = history.history[\"iou\"]\n",
        "  numpy_iou_history = np.array(iou_history)\n",
        "  np.savetxt(save_model_path[:-3]+\"_iou_history.txt\", numpy_iou_history, delimiter=\",\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Omar_DcXM_h0"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Transpose Convolution 1**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "P1dQZOF5fSYm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildModel(empty_model):\n",
        "\n",
        "    inputs = Input((768, 768, 3))\n",
        "\n",
        "    c0 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "    c0 = Dropout(0.1) (c0)\n",
        "    c0 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c0)\n",
        "    p0 = MaxPooling2D((2, 2)) (c0)\n",
        "\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p0)\n",
        "    c1 = Dropout(0.1) (c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "    c2 = Dropout(0.1) (c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "    c3 = Dropout(0.2) (c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "    c4 = Dropout(0.2) (c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "    c5 = Dropout(0.3) (c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "    c6 = Dropout(0.2) (c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "    c7 = Dropout(0.2) (c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "    c8 = Dropout(0.1) (c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "    c9 = Dropout(0.1) (c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "    u10 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c9)\n",
        "    u10 = concatenate([u10, c0], axis=3)\n",
        "    c10 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u10)\n",
        "    c10 = Dropout(0.1) (c10)\n",
        "    c10 = Conv2D(8, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c10)\n",
        "\n",
        "    outputs =Conv2D(1, (1, 1), activation='sigmoid') (c10)\n",
        "\n",
        "    empty_model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    #tc_u_net_model.summary()\n",
        "    return empty_model\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vXZT_HHy15_2",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train Model 1\n",
        "val1_tc_u_net_model_N1 = None\n",
        "val2_tc_u_net_model_N1 = None\n",
        "val3_tc_u_net_model_N1 = None\n",
        "val4_tc_u_net_model_N1 = None\n",
        "learn(\"./val1_tc_u_net_model_N1.h5\", training_generator1, validation_generator1, buildModel(val1_tc_u_net_model_N1))\n",
        "learn(\"./val2_tc_u_net_model_N1.h5\", training_generator2, validation_generator2, buildModel(val2_tc_u_net_model_N1))\n",
        "learn(\"./val3_tc_u_net_model_N1.h5\", training_generator3, validation_generator3, buildModel(val3_tc_u_net_model_N1))\n",
        "learn(\"./val4_tc_u_net_model_N1.h5\", training_generator4, validation_generator4, buildModel(val4_tc_u_net_model_N1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nvz4uQdA-arq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Bilinear Interpolation**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "X5alLL3GjttZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildModel2(empty_model):\n",
        "    inputs = Input((768, 768, 3))\n",
        "\n",
        "    c0 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "    c0 = Dropout(0.1) (c0)\n",
        "    c0 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c0)\n",
        "    p0 = MaxPooling2D((2, 2)) (c0)\n",
        "\n",
        "    c1 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p0)\n",
        "    c1 = Dropout(0.1) (c1)\n",
        "    c1 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "    c2 = Dropout(0.2) (c2)\n",
        "    c2 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "    c3 = Dropout(0.2) (c3)\n",
        "    c3 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "\n",
        "    u1 = UpSampling2D(size=(2, 2), data_format=None) (c3)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u1)\n",
        "    c4 = Dropout(0.2) (c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "\n",
        "    u2 = UpSampling2D(size=(2, 2), data_format=None) (c4)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u2)\n",
        "    c5 = Dropout(0.2) (c5)\n",
        "    c5 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "    u3 = UpSampling2D(size=(2, 2), data_format=None) (c5)\n",
        "    c6 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u3)\n",
        "    c6 = Dropout(0.2) (c6)\n",
        "    c6 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c6)\n",
        "\n",
        "    empty_model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    return empty_model\n",
        "    #bi_u_net_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C6EEbr_79Z7G",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train model 2\n",
        "val1_tc_u_net_model_N2 = None\n",
        "val2_tc_u_net_model_N2 = None\n",
        "val3_tc_u_net_model_N2 = None\n",
        "val4_tc_u_net_model_N2 = None\n",
        "learn(\"./val1_tc_u_net_model_N2.h5\", training_generator2, validation_generator2, buildModel2(val1_tc_u_net_model_N2))\n",
        "learn(\"./val2_tc_u_net_model_N2.h5\", training_generator2, validation_generator2, buildModel2(val2_tc_u_net_model_N2))\n",
        "learn(\"./val3_tc_u_net_model_N2.h5\", training_generator3, validation_generator3, buildModel2(val3_tc_u_net_model_N2))\n",
        "learn(\"./val4_tc_u_net_model_N2.h5\", training_generator4, validation_generator4, buildModel2(val4_tc_u_net_model_N2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8r15-v7-Fvu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Transposed Convolution 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b4sBDMcf9Z7J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildModel3(empty_model):\n",
        "\n",
        "    inputs = Input((768, 768, 3))\n",
        "\n",
        "    c0 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
        "    c0 = Dropout(0.1) (c0)\n",
        "    c0 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c0)\n",
        "    p0 = MaxPooling2D((2, 2)) (c0)\n",
        "\n",
        "    c1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p0)\n",
        "    c1 = Dropout(0.1) (c1)\n",
        "    c1 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "    c2 = Dropout(0.1) (c2)\n",
        "    c2 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "    c3 = Dropout(0.2) (c3)\n",
        "    c3 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = Conv2D(1024, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "\n",
        "    u5 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same') (c4)\n",
        "    u5 = concatenate([u5, c3])\n",
        "    c5 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u5)\n",
        "    c5 = Dropout(0.2) (c5)\n",
        "    c5 = Conv2D(512, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "    u6 = concatenate([u6, c2])\n",
        "    c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "    c6 = Dropout(0.2) (c6)\n",
        "    c6 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "    u7 = concatenate([u7, c1])\n",
        "    c7 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "    c7 = Dropout(0.1) (c7)\n",
        "    c7 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "    u8 = concatenate([u8, c0])\n",
        "    c8 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "    c8 = Dropout(0.1) (c8)\n",
        "    c8 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c8)\n",
        "\n",
        "    empty_model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    empty_model.summary()\n",
        "    return empty_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wd9RXbxx9Z7O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train model 3\n",
        "val1_tc_u_net_model_N3 = None\n",
        "val2_tc_u_net_model_N3 = None\n",
        "val3_tc_u_net_model_N3 = None\n",
        "val4_tc_u_net_model_N3 = None\n",
        "learn(\"./val1_tc_u_net_model_N3.h5\", training_generator2, validation_generator2, buildModel3(val1_tc_u_net_model_N3))\n",
        "learn(\"./val2_tc_u_net_model_N3.h5\", training_generator2, validation_generator2, buildModel3(val2_tc_u_net_model_N3))\n",
        "learn(\"./val3_tc_u_net_model_N3.h5\", training_generator3, validation_generator3, buildModel3(val3_tc_u_net_model_N3))\n",
        "learn(\"./val4_tc_u_net_model_N3.h5\", training_generator4, validation_generator4, buildModel3(val4_tc_u_net_model_N3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kTmIvd_1OjsQ"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "Vis5eqq-7JWT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define back_iou evaluation function\n",
        "def back_iou_eval(model, weights, generator, name):\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss = iou_loss, metrics=[back_iou])\n",
        "    model.load_weights(weights)\n",
        "\n",
        "    scores = model.evaluate_generator(generator=generator, verbose=1, workers=30, use_multiprocessing=True)\n",
        "\n",
        "    print(name)\n",
        "    print(scores[1])\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dG1chsJL7JWW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define iou evaluation function\n",
        "def iou_eval(model, weights, generator, name):\n",
        "    model.compile(optimizer=Adam(lr=1e-4), loss = iou_loss, metrics=[iou])\n",
        "    model.load_weights(weights)\n",
        "\n",
        "    scores = model.evaluate_generator(generator=generator, verbose=1, workers=30, use_multiprocessing=True)\n",
        "\n",
        "    print(name)\n",
        "    print(scores[1])\n",
        "    print(\"---------------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mykUVE9v7JWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating ship evaluation generators\n",
        "params = {'batch_size': 8,\n",
        "          'dim': (768,768),\n",
        "          'n_channels': 3,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "complete_data_list = os.listdir(\"./test_label_ship/\")\n",
        "for i, string in enumerate(complete_data_list):\n",
        "    complete_data_list[i] = string[:-5]\n",
        "    \n",
        "print(str(complete_data_list[0]))\n",
        "print(len(complete_data_list))\n",
        "\n",
        "\n",
        "test_ship_generator = DataGenerator(complete_data_list, \"./test_data/\", **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lXnYT-9I7JWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating all evaluation generators\n",
        "params = {'batch_size': 3,\n",
        "          'dim': (768,768),\n",
        "          'n_channels': 3,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "ship_data_list = os.listdir(\"./test_label_ship/\")\n",
        "for i, string in enumerate(ship_data_list):\n",
        "    ship_data_list[i] = string[:-5]\n",
        "    \n",
        "complete_data_list = os.listdir(\"./test_label_no_ship/\")\n",
        "for i, string in enumerate(complete_data_list):\n",
        "    complete_data_list[i] = string[:-5]\n",
        "    \n",
        "complete_data_list.extend(ship_data_list)\n",
        "shuffle(complete_data_list)\n",
        "complete_data_list = complete_data_list[0:int(np.floor(len(complete_data_list) / 4))]\n",
        "\n",
        "print(str(complete_data_list[0]))\n",
        "print(len(complete_data_list))\n",
        "\n",
        "\n",
        "test_all_generator = DataGenerator(complete_data_list, \"./test_data/\", **params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "007pfHjL7JWe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate IOU on Test**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "iHCdFnJt7JWf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate transpose convolution model 1 IOU on Test\n",
        "model = None\n",
        "iou_eval(buildModel(model), \"./val1_tc_u_net_model_N1.h5\", test_ship_generator, \"back_iou_val1_N1\")\n",
        "model = None\n",
        "iou_eval(buildModel(model), \"./val2_tc_u_net_model_N1.h5\", test_ship_generator, \"back_iou_val2_N1\")\n",
        "model = None\n",
        "iou_eval(buildModel(model), \"./val3_tc_u_net_model_N1.h5\", test_ship_generator, \"back_iou_val3_N1\")\n",
        "model = None\n",
        "iou_eval(buildModel(model), \"./val4_tc_u_net_model_N1.h5\", test_ship_generator, \"back_iou_val4_N1\")\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Evaluate Bilinear Interpolation model IOU on Test\n",
        "model = None\n",
        "iou_eval(buildModel2(model), \"./val1_tc_u_net_model_N2.h5\", test_ship_generator, \"back_iou_val1_N2\")\n",
        "model = None\n",
        "iou_eval(buildModel2(model), \"./val2_tc_u_net_model_N2.h5\", test_ship_generator, \"back_iou_val2_N2\")\n",
        "model = None\n",
        "iou_eval(buildModel2(model), \"./val3_tc_u_net_model_N2.h5\", test_ship_generator, \"back_iou_val3_N2\")\n",
        "model = None\n",
        "iou_eval(buildModel2(model), \"./val4_tc_u_net_model_N2.h5\", test_ship_generator, \"back_iou_val4_N2\")\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Evaluate transpose convolution model 2 IOU on Test\n",
        "model = None\n",
        "iou_eval(buildModel3(model), \"./val1_tc_u_net_model_N3.h5\", test_ship_generator, \"back_iou_val1_N3\")\n",
        "model = None\n",
        "iou_eval(buildModel3(model), \"./val2_tc_u_net_model_N3.h5\", test_ship_generator, \"back_iou_val2_N3\")\n",
        "model = None\n",
        "iou_eval(buildModel3(model), \"./val3_tc_u_net_model_N3.h5\", test_ship_generator, \"back_iou_val3_N3\")\n",
        "model = None\n",
        "iou_eval(buildModel3(model), \"./val4_tc_u_net_model_N3.h5\", test_ship_generator, \"back_iou_val4_N3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMr8rpT07JWh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate Back_IOU on Validation**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "D9VyX0MV7JWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate transpose convolution model 1 on Back-IoU\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val1_tc_u_net_model_N1.h5\", validation_generator1, \"back_iou_val1_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val2_tc_u_net_model_N1.h5\", validation_generator2, \"back_iou_val2_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val3_tc_u_net_model_N1.h5\", validation_generator3, \"back_iou_val3_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val4_tc_u_net_model_N1.h5\", validation_generator3, \"back_iou_val4_N1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0t3OAHL7JWp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate bilinear Interpolation model on Back-IoU\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val1_tc_u_net_model_N2.h5\", validation_generator1, \"back_iou_val1_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val2_tc_u_net_model_N2.h5\", validation_generator2, \"back_iou_val2_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val3_tc_u_net_model_N2.h5\", validation_generator3, \"back_iou_val3_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val4_tc_u_net_model_N2.h5\", validation_generator3, \"back_iou_val4_N2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-M_OZx_a7JWu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate transpose convolution model 2 on Back-IoU\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val1_tc_u_net_model_N3.h5\", validation_generator1, \"back_iou_val1_N3\")\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val2_tc_u_net_model_N3.h5\", validation_generator2, \"back_iou_val2_N3\")\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val3_tc_u_net_model_N3.h5\", validation_generator1, \"back_iou_val3_N3\")\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val4_tc_u_net_model_N3.h5\", validation_generator2, \"back_iou_val4_N3\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBchhdVA7JWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate Back_IOU on Test**\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "rjjJGIp17JWx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Evaluate transpose convolution model 1 on Test\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val1_tc_u_net_model_N1.h5\", test_all_generator, \"back_iou_val1_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val2_tc_u_net_model_N1.h5\", test_all_generator, \"back_iou_val2_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val3_tc_u_net_model_N1.h5\", test_all_generator, \"back_iou_val3_N1\")\n",
        "model = None\n",
        "back_iou_eval(buildModel(model), \"./val4_tc_u_net_model_N1.h5\", test_all_generator, \"back_iou_val4_N1\")\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Evaluate Bilinear Interpolation model on Test\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val1_tc_u_net_model_N2.h5\", test_all_generator, \"back_iou_val1_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val2_tc_u_net_model_N2.h5\", test_all_generator, \"back_iou_val2_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val3_tc_u_net_model_N2.h5\", test_all_generator, \"back_iou_val3_N2\")\n",
        "model = None\n",
        "back_iou_eval(buildModel2(model), \"./val4_tc_u_net_model_N2.h5\", test_all_generator, \"back_iou_val4_N2\")\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "# Evaluate transpose convolution model 2 on Test\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val1_tc_u_net_model_N3.h5\", test_all_generator, \"back_iou_val1_N3\")\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val2_tc_u_net_model_N3.h5\", test_all_generator, \"back_iou_val2_N3\")\n",
        "model = None\n",
        "iou_eval(buildModel3(model), \"./val3_tc_u_net_model_N3.h5\", test_all_generator, \"back_iou_val3_N3\")\n",
        "model = None\n",
        "back_iou_eval(buildModel3(model), \"./val4_tc_u_net_model_N3.h5\", test_all_generator, \"back_iou_val4_N3\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}